{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " * Serving Flask app '__main__'\n",
                        " * Debug mode: on\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
                        " * Running on http://127.0.0.1:5000\n",
                        "Press CTRL+C to quit\n",
                        " * Restarting with watchdog (windowsapi)\n"
                    ]
                }
            ],
            "source": [
                "from flask import Flask, render_template, request\n",
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "@app.route('/')\n",
                "def index():\n",
                "    return render_template('index.html')\n",
                "\n",
                "@app.route('/import_data', methods=['POST'])\n",
                "def import_data():\n",
                "    if request.method == 'POST':\n",
                "        # Lấy đường dẫn thư mục từ form\n",
                "        folder_path = request.form['folder_path']\n",
                "        \n",
                "        # Đọc các file CSV trong thư mục\n",
                "        dataframes = read_csv_files_in_folder(folder_path)\n",
                "        \n",
                "        # Thực hiện xử lý dữ liệu hoặc lưu trữ chúng tùy ý\n",
                "        \n",
                "        return \"Dữ liệu đã được import thành công từ thư mục: {}\".format(folder_path)\n",
                "\n",
                "def read_csv_files_in_folder(folder_path):\n",
                "    dfs = []\n",
                "    for file_name in os.listdir(folder_path):\n",
                "        if file_name.endswith('.csv'):\n",
                "            file_path = os.path.join(folder_path, file_name)\n",
                "            df = pd.read_csv(file_path)\n",
                "            dfs.append(df)\n",
                "    return dfs\n",
                "\n",
                "if __name__ == '__main__':\n",
                "    app.run(debug=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Aufinia 7\\AppData\\Local\\Temp\\ipykernel_8388\\3011707537.py:15: DtypeWarning: Columns (0,3,4,5,17,18,19,20,26,28,35,46,48,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  DF_SQLITE = pd.read_csv(DV_FILE_PATH_SQLITE, delimiter='\\t', encoding='utf-8', encoding_errors='ignore')\n",
                        "C:\\Users\\Aufinia 7\\AppData\\Local\\Temp\\ipykernel_8388\\3011707537.py:16: DtypeWarning: Columns (0,3,4,5,17,18,19,20,26,28,35,46,48,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  DF_PYTHON = pd.read_csv(DV_FILE_PATH_PYTHON, delimiter='\\t', encoding='utf-8', encoding_errors='ignore')\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "# Get the current directory path\n",
                "current_directory = os.getcwd()\n",
                "\n",
                "# Specify the file names you want to read\n",
                "DV_FILE_NAME_SQLITE = 'B_SS00_SS04_11_IT_SKB1_SKA1_ACC_DESCS_test_SQL.csv'\n",
                "DV_FILE_NAME_PYTHON = 'B_SS00_SS04_11_IT_SKB1_SKA1_ACC_DESCS.csv'\n",
                "# Join the file names with the current directory path to create the full file paths\n",
                "DV_FILE_PATH_SQLITE = os.path.join(current_directory, DV_FILE_NAME_SQLITE)\n",
                "DV_FILE_PATH_PYTHON = os.path.join(current_directory, DV_FILE_NAME_PYTHON)\n",
                "\n",
                "# Read CSV files into DataFrames\n",
                "DF_SQLITE = pd.read_csv(DV_FILE_PATH_SQLITE, delimiter='\\t', encoding='utf-8', encoding_errors='ignore')\n",
                "DF_PYTHON = pd.read_csv(DV_FILE_PATH_PYTHON, delimiter='\\t', encoding='utf-8', encoding_errors='ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['SKB1_BUKRS', 'SKB1_ERDAT', 'SKB1_ERNAM', 'SKB1_HBKID', 'SKB1_HKTID',\n",
                        "       'SKB1_SAKNR', 'SKB1_WAERS', 'SKB1_XGKON', 'SKB1_STEXT', 'SKB1_FIPLS',\n",
                        "       'SKB1_XINTB', 'SKB1_XOPVW', 'SKB1_BEWGP', 'SKB1_XLGCLR', 'SKB1_MITKZ',\n",
                        "       'ZF_KEY_JN_USR21_SKB1', 'ZF_KEY_JN_USER_ADDR_SKA1',\n",
                        "       'ZF_KEY_JN_T001_SKB1', 'ZF_KEY_JN_T012K_SKB1', 'ZF_KEY_JN_REGUH_SKB1',\n",
                        "       'ZF_KEY_JN_FEBKO_SKB1', 'USR21_BNAME_SKB1', 'USR21_KOSTL_SKB1',\n",
                        "       'USR21_PERSNUMBER_SKB1', 'USER_ADDR_BNAME_SKA1',\n",
                        "       'USER_ADDR_NAME_TEXTC_SKA1', 'T012K_BUKRS_SKB1', 'T012K_HKONT_SKB1',\n",
                        "       'T012K_HBKID_SKB1', 'REGUH_ZBUKR_SKB1', 'REGUH_HKONT_SKB1',\n",
                        "       'ZF_REGUH_HKONT_COUNT', 'FEBKO_BUKRS_SKB1', 'FEBKO_HKONT_SKB1',\n",
                        "       'ZF_FEBKO_HKONT_COUNT', 'T001_BUKRS_SKB1', 'T001_BUTXT_SKB1',\n",
                        "       'T001_KTOPL_SKB1', 'T001_WAERS_SKB1', 'ZF_KEY_JN_SKA1_SKB1',\n",
                        "       'SKA1_KTOKS', 'SKA1_FUNC_AREA', 'SKA1_ERNAM', 'SKA1_ERDAT',\n",
                        "       'SKA1_XBILK', 'SKA1_GVTYP', 'SKA1_BILKT', 'SKA1_XLOEV', 'SKA1_XSPEA',\n",
                        "       'SKA1_XSPEB', 'SKA1_XSPEP', 'ZF_KEY_JN_SKAT_SKA1',\n",
                        "       'ZF_KEY_JN_T077Z_SKA1', 'ZF_KEY_JN_TFKBT_SKA1', 'SKAT_SPRAS_SKA1',\n",
                        "       'SKAT_TXT20_SKA1', 'SKAT_TXT50_SKA1', 'T077Z_KTOPL_SKA1',\n",
                        "       'T077Z_KTOKS_SKA1', 'T077Z_TXT30_SKA1', 'TFKBT_FKBTX_SKA1',\n",
                        "       'ZF_SAKNR_PL_OR_BS', 'ZF_SAKNR_PL_OR_BS_W_DESC', 'ZF_KTOKS_T077Z_TXT30',\n",
                        "       'ZF_KEY_JN_ACCDESC_SKA1', 'ZF_SAKNR_CONFIG_DESC'],\n",
                        "      dtype='object')\n"
                    ]
                }
            ],
            "source": [
                "print(DF_SQLITE.columns)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Columns from the two DataFrames are the same.\n"
                    ]
                }
            ],
            "source": [
                "DF_COLUMN_NAME = \"ZF_KEY_JN_ACCDESC_SKA1\"\n",
                "\n",
                "DF_SQLITE[DF_COLUMN_NAME] = DF_SQLITE[DF_COLUMN_NAME].astype(str).str.strip()\n",
                "DF_PYTHON[DF_COLUMN_NAME] = DF_PYTHON[DF_COLUMN_NAME].astype(str).str.strip()\n",
                "DF_DIFF_CHECK = DF_SQLITE[DF_COLUMN_NAME].reset_index(drop=True).compare(DF_PYTHON[DF_COLUMN_NAME].reset_index(drop=True))\n",
                "DF_DIFF_RENAMED = DF_DIFF_CHECK.rename(columns={'self': 'SQLITE', 'other': 'PYTHON'})\n",
                "\n",
                "if not DF_DIFF_RENAMED.empty:\n",
                "    DF_DIFF_RENAMED['Iloc Difference'] = DF_DIFF_RENAMED.index\n",
                "\n",
                "    print(\"Result from two different DataFrames. Detailed difference:\")\n",
                "    print(DF_DIFF_RENAMED)\n",
                "    DF_DIFF_RENAMED.to_csv('difference_results.csv', index=False)\n",
                "else:\n",
                "    print(\"Columns from the two DataFrames are the same.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
